{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luficerg/hugging-face/blob/master/course/datasets_and_dataframes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmGzuEa5M-Br"
      },
      "source": [
        "This notebook regroups the code sample of the video below, which is a part of the [Hugging Face course](https://huggingface.co/course)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5wHBd3IEM-B1",
        "outputId": "5bc89dc3-4353-487d-d257-d2294fe942e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tfcY1067A5Q?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tfcY1067A5Q?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmFG_WY4M-B8"
      },
      "source": [
        "Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYoWM0JoM-B9"
      },
      "outputs": [],
      "source": [
        "! pip install datasets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WGqpDSNM-B-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"swiss_judgment_prediction\", \"all_languages\", split=\"train\")\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-DjS7FiM-B-"
      },
      "outputs": [],
      "source": [
        "# Convert the output format to pandas.DataFrame\n",
        "dataset.set_format(\"pandas\")\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9lpDwBrM-B_"
      },
      "outputs": [],
      "source": [
        "dataset.__getitem__(0)\n",
        "\n",
        "dataset.set_format(\"pandas\")\n",
        "\n",
        "dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1-tIPr_M-CA"
      },
      "outputs": [],
      "source": [
        "df = dataset.to_pandas()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxK74iCmM-CB"
      },
      "outputs": [],
      "source": [
        "# How are languages distributed across regions?\n",
        "df.groupby(\"region\")[\"language\"].value_counts()\n",
        "\n",
        "# Which legal area is most common?\n",
        "df[\"legal area\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL3Lw-IuM-CC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load a pretrained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# Tokenize the `text` column\n",
        "dataset.map(lambda x : tokenizer(x[\"text\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahybVRyPM-CD"
      },
      "outputs": [],
      "source": [
        "# Reset back to Arrow format\n",
        "dataset.reset_format()\n",
        "# Now we can tokenize!\n",
        "dataset.map(lambda x : tokenizer(x[\"text\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Datasets + DataFrames = ❤️",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}